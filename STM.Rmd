---
title: "STM"
author: "Fernando Muñoz"
date: "27 de septiembre de 2018"
output: html_document
---

# Extracción de los temas de todo el corpus

## Paquetes

```
library(tidytext)
library(tidyverse)
library(stopwords)
library(quanteda)
library(stm)
library(Rtsne)
library(rsvd)
library(geometry)
library(knitr)
library(plotrix)
```

## Preparación de los inputs y filtrado de stopwords

```
# Creamos un df de stopwords para que sea el input de anti_join
stopwords<-data.frame(data_stopwords_stopwordsiso$es, 
                      rep("ISO", length(data_stopwords_stopwordsiso$es)))
colnames(stopwords)<-c("word", "lexicon")

# Creamos un df con articulos e id
articulos<-tibble(c(1:length(noticias.df$articulo)), 
                  as.character(noticias.df$articulo), 
                  as.character(noticias.df$medio),
                  as.character(noticias.df$autor),
                  as.character(noticias.df$fecha))
colnames(articulos)<-c("id", "articulo", "medio", "autor", "fecha")

# Ordenamos y filtramos stopwords
tidy_news <- articulos %>%
  unnest_tokens(word, articulo) %>%
  anti_join(stopwords) %>%
  anti_join(stop_words)

# Creamos un dfm con los datos
news.dfm <- tidy_news %>%
  count(id, word, sort = TRUE) %>%
  tidytext::cast_dfm(id, word, n)
  
```

## Extracción del número de temas

```
# Extraemos los temas sin poner una cantidad
news.free.tm.swo <- stm(news.dfm, K = 0, verbose = FALSE, init.type = "Spectral")
labelTopics(news.free.tm.swo)
plot.STM(news.free.tm.swo ,type="summary", xlim=c(0, 0.1), n=7)

topicQuality(news.free.tm.swo, news.dfm)

# Buscamos una cantidad más precisa, pero antes preparamos los inputs
# y ampliamos la memoria
processed<-textProcessor(articulos$articulo,customstopwords = stopwords$word)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta,
                     lower.thresh = 5,upper.thresh = 6587)
palabras<-unique(tidy_news$word)
memory.limit(410241024*1024)

sk<-searchK(out$documents,palabras,K=c(10, 20, 30, 40, 50))
knitr::kable(sk$results)
plot(sk)

# En base a los resultados:
sk35_40<-searchK(out$documents, palabras, K=c(35, 36, 37, 38, 39, 40))
knitr::kable(sk35_40$results)
plot(sk35_40)

``# Extraemos los temas sin poner una cantidad
news.free.tm.swo <- stm(news.dfm, K = 0, verbose = FALSE, init.type = "Spectral")
labelTopics(news.free.tm.swo)
plot.STM(news.free.tm.swo ,type="summary", xlim=c(0, 0.1), n=7)

topicQuality(news.free.tm.swo, news.dfm)

# Buscamos una cantidad más precisa, pero antes preparamos los inputs
# y ampliamos la memoria
processed<-textProcessor(articulos$articulo,customstopwords = stopwords$word)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta,
                     lower.thresh = 5,upper.thresh = 6587)
palabras<-unique(tidy_news$word)
memory.limit(410241024*1024)

sk<-searchK(out$documents,palabras,K=c(10, 20, 30, 40, 50))
knitr::kable(sk$results)
plot(sk)

# En base a los resultados:
sk35_40<-searchK(out$documents, palabras, K=c(35, 36, 37, 38, 39, 40))
knitr::kable(sk35_40$results)
plot(sk35_40)

```

## Extracción de temas

```
# Parece que el número apropiado de temas es 37

news.37.tm <- stm(news.dfm, K = 37, verbose = FALSE, init.type = "Spectral")
labelTopics(news.37.tm)
plot.STM(news.37.tm,type="summary",xlim=c(0,0.1), n =7)
topicQuality(news.37.tm, news.dfm)

# Graficaremos los temas en un diagrama de tarta, pero para eso tenemos que crear
# una tabla con la proporción en la que aparecen

temas<-c("Política", "Periodismo", "Narrativa", "Actualidad", "Toros", "M?sica", 
         "Literatura", "Música", "Fútbol", "Actualidad", "Televisión", "Pol?tica", 
         "Protección cacerías", "Religión", "Arte", "Literatura", "Televisi?n",
         "Periodismo", "Arte", "Arte", "Literatura", "Música", "Cine", "Literatura",
         "Música", "Cómic", "Cine", "Literatura", "Literatura", "Política", "Teatro",
         "Literatura", "Pol?tica", "Música", "Toros", "Cine", "Política")
temas<-table(temas)
temas<-data.frame(temas)
colnames(temas)<-c("Tema", "Frecuencia")

```

## Graficado

```
plotrix::pie3D(temas$Frecuencia,labels=paste(temas$Tema, temas$Frecuencia,
                                             collapse = NULL, sep= " "),
               explode=0.1, main="Temas en el corpus")

# Buscar documentos claramente de un tema


medio <- estimateEffect(1:37 ~ medio, news.37.tm, articulos)
plot.estimateEffect(medio, "medio", topics = c(28), 
                    method = "pointestimate", main = "Proporci?n tem?tica por medio")

autor <- estimateEffect(1:37 ~ autor, news.37.tm, articulos)
plot.estimateEffect(prep, "medio", topics = c(28), 
                    method = "pointestimate", main = "Proporci?n tem?tica por medio")

```



# Extracción de los temas de ABC Cultural

## Paquetes

```
library(tidytext)
library(tidyverse)
library(stopwords)
library(quanteda)
library(stm)
library(Rtsne)
library(rsvd)
library(geometry)
library(knitr)
library(plotrix)
library(igraph)

```



## Creación de inputs y filtrado de stopwords

```

# Creamos un df de stopwords para que sea el input de anti_join

stopwords<-data.frame(data_stopwords_stopwordsiso$es, 
                      rep("ISO", length(data_stopwords_stopwordsiso$es)))
colnames(stopwords)<-c("word", "lexicon")

# Creamos un df con articulos e id
articulos<-tibble(c(1:length(noticias.df$articulo)), 
                  as.character(noticias.df$articulo), 
                  as.character(noticias.df$medio),
                  as.character(noticias.df$autor),
                  as.character(noticias.df$fecha))
colnames(articulos)<-c("id", "articulo", "medio", "autor", "fecha")
ABCCultural<-articulos[which(articulos$medio=="ABC Cultural"),]

# Ordenamos y filtramos stopwords
tidy_news <- ABCCultural %>%
  unnest_tokens(word, articulo) %>%
  anti_join(stopwords) %>%
  anti_join(stop_words)

# Creamos un dfm con los datos
news.dfm <- tidy_news %>%
  count(id, word, sort = TRUE) %>%
  tidytext::cast_dfm(id, word, n)
```

## Búsqueda de la cantidad de temas apropiada

```
# Extraemos los temas sin poner una cantidad
news.free.tm.swo <- stm(news.dfm, K = 0, verbose = FALSE, init.type = "Spectral")
labelTopics(news.free.tm.swo)
plot.STM(news.free.tm.swo ,type="summary", xlim=c(0, 0.1), n=7)

topicQuality(news.free.tm.swo, news.dfm)

# Buscamos una cantidad m?s precisa, pero antes preparamos los inputs
# y ampliamos la memoria
processed<-textProcessor(ABCCultural$articulo,customstopwords = stopwords$word)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta,
                     lower.thresh = 5,upper.thresh = 393)
palabras<-unique(tidy_news$word)
memory.limit(410241024*1024)

sk<-searchK(out$documents,palabras,K=c(10, 20, 30, 40, 50))
knitr::kable(sk$results)
plot(sk)

# En base a los resultados:
sk17_23<-searchK(out$documents, palabras, K=c(17,18,19,20,21,22,23))
knitr::kable(sk17_23$results)
plot(sk17_23)
```

## Extracción del número de temas

```
# Parece que el n?mero apropiado de temas es 37

news.18.tm <- stm(news.dfm, K = 18, verbose = FALSE, init.type = "Spectral")
labelTopics(news.18.tm, n=10)
plot.STM(news.18.tm,type="summary",xlim=c(0,0.2), n =7)
topicQuality(news.18.tm, news.dfm)



temas<-c("M?sica", "M?sica", "Arte", "Libertad", "Lenguaje", "Restaturaciones",
         "Literatura", "Cine", "Arte", "Toros", "Teatro", "Arte", "Historia",
         "M?sica", "M?sica", "Arte", "Literatura")
temas<-table(temas)
temas<-data.frame(temas)
colnames(temas)<-c("Tema", "Frecuencia")
```

## Graficado

```
plotrix::pie3D(temas$Frecuencia,labels=paste(temas$Tema, temas$Frecuencia,
                                             collapse = NULL, sep= " "),
               explode=0.1, main="Cultura seg?n ABC Cultural")


```


# Extracción de los temas de El País

## Paquetes

```
library(tidytext)
library(tidyverse)
library(stopwords)
library(quanteda)
library(stm)
library(Rtsne)
library(rsvd)
library(geometry)
library(knitr)
library(plotrix)
library(igraph)

```

## Creación de inputs y filtrado de stopwords

```
# Creamos un df de stopwords para que sea el input de anti_join
stopwords<-data.frame(data_stopwords_stopwordsiso$es, 
                      rep("ISO", length(data_stopwords_stopwordsiso$es)))
colnames(stopwords)<-c("word", "lexicon")

# Creamos un df con articulos e id
articulos<-tibble(c(1:length(noticias.df$articulo)), 
                  as.character(noticias.df$articulo), 
                  as.character(noticias.df$medio),
                  as.character(noticias.df$autor),
                  as.character(noticias.df$fecha))
colnames(articulos)<-c("id", "articulo", "medio", "autor", "fecha")
ElPais<-articulos[which(articulos$medio=="El Pais"),]

# Ordenamos y filtramos stopwords
tidy_news <- ElPais %>%
  unnest_tokens(word, articulo) %>%
  anti_join(stopwords) %>%
  anti_join(stop_words)

# Creamos un dfm con los datos
news.dfm <- tidy_news %>%
  count(id, word, sort = TRUE) %>%
  tidytext::cast_dfm(id, word, n)

```

## Búsqueda de la cantidad de temas apropiada

```
# Extraemos los temas sin poner una cantidad
news.free.tm.swo <- stm(news.dfm, K = 0, verbose = FALSE, init.type = "Spectral")
labelTopics(news.free.tm.swo)
plot.STM(news.free.tm.swo ,type="summary", xlim=c(0, 0.1), n=7)

topicQuality(news.free.tm.swo, news.dfm)

# Buscamos una cantidad m?s precisa, pero antes preparamos los inputs
# y ampliamos la memoria
processed<-textProcessor(ElPais$articulo,customstopwords = stopwords$word)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta,
                     lower.thresh = 5,upper.thresh = 3183)
palabras<-unique(tidy_news$word)
memory.limit(410241024*1024)

sk<-searchK(out$documents,palabras,K=c(10, 20, 30, 40))
knitr::kable(sk$results)
plot(sk)

# En base a los resultados:
sk14_21<-searchK(out$documents, palabras, K=c(14,15,16,17,18,19,20,21))
knitr::kable(sk17_23$results)
plot(sk14_21)
```


## Extracción de los temas

```
# Parece que el n?mero apropiado de temas es 15

news.15.tm <- stm(news.dfm, K = 15, verbose = FALSE, init.type = "Spectral")
labelTopics(news.15.tm, n=10)
plot.STM(news.15.tm,type="summary",xlim=c(0,0.2), n =7)
topicQuality(news.15.tm, news.dfm)


temas<-c("Periodismo", "M?sica", "Cultura", "M?sica", "M?sica", "Televisi?n",
         "Literatura", "Toros", "Literatura", "Teatro", "Televisi?n", "Literatura",
         "Arte")
temas<-table(temas)
temas<-data.frame(temas)
colnames(temas)<-c("Tema", "Frecuencia")

```

## Graficado

```
plotrix::pie3D(temas$Frecuencia,labels=paste(temas$Tema, temas$Frecuencia,
                                             collapse = NULL, sep= " "),
               explode=0.1, main="Cultura seg?n El Pa?s")

```


# Extracción de los temas del Diario Sur

## Paquetes

```
library(tidytext)
library(tidyverse)
library(stopwords)
library(quanteda)
library(stm)
library(Rtsne)
library(rsvd)
library(geometry)
library(knitr)
library(plotrix)
library(igraph)

```


## Creación de inputs y filtrado de stopwords

```
# Creamos un df de stopwords para que sea el input de anti_join
stopwords<-data.frame(data_stopwords_stopwordsiso$es, 
                      rep("ISO", length(data_stopwords_stopwordsiso$es)))
colnames(stopwords)<-c("word", "lexicon")

# Creamos un df con articulos e id
articulos<-tibble(c(1:length(noticias.df$articulo)), 
                  as.character(noticias.df$articulo), 
                  as.character(noticias.df$medio),
                  as.character(noticias.df$autor),
                  as.character(noticias.df$fecha))
colnames(articulos)<-c("id", "articulo", "medio", "autor", "fecha")
DiarioSur<-articulos[which(articulos$medio=="Diario Sur"),]

# Ordenamos y filtramos stopwords
tidy_news <- DiarioSur %>%
  unnest_tokens(word, articulo) %>%
  anti_join(stopwords) %>%
  anti_join(stop_words)

# Creamos un dfm con los datos
news.dfm <- tidy_news %>%
  count(id, word, sort = TRUE) %>%
  tidytext::cast_dfm(id, word, n)

```


## Búsqueda de la cantidad de temas apropiada

```
# Extraemos los temas sin poner una cantidad
news.free.tm.swo <- stm(news.dfm, K = 0, verbose = FALSE, init.type = "Spectral")
labelTopics(news.free.tm.swo)
plot.STM(news.free.tm.swo ,type="summary", xlim=c(0, 0.1), n=7)

topicQuality(news.free.tm.swo, news.dfm)

# Buscamos una cantidad m?s precisa, pero antes preparamos los inputs
# y ampliamos la memoria
processed<-textProcessor(DiarioSur$articulo,customstopwords = stopwords$word)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta,
                     lower.thresh = 5,upper.thresh = 3183)
palabras<-unique(tidy_news$word)
memory.limit(410241024*1024)

sk<-searchK(out$documents,palabras,K=c(10, 20, 30, 40))
knitr::kable(sk$results)
plot(sk)

# En base a los resultados:
sk16_22<-searchK(out$documents, palabras, K=c(16,17,18,19,20,21,22))
knitr::kable(sk17_23$results)
plot(sk16_22)

```



## Extracción de los temas

```
# Parece que el n?mero apropiado de temas es 21

news.21.tm <- stm(news.dfm, K = 21, verbose = FALSE, init.type = "Spectral")
labelTopics(news.21.tm, n=10)
plot.STM(news.21.tm,type="summary",xlim=c(0,0.2), n =7)
topicQuality(news.21.tm, news.dfm)


temas<-c("M?sica", "M?sica", "Cine", "M?sica", "Historia", "Cine", "Cine",
         "Literatura", "Cine", "Televisi?n", "Literatura", "M?sica", "Arte",
         "Literatura", "C?mic", "Cine", "Toros", "Literatura", "Televisi?n",
         "Cultura", "Cultura")
temas<-table(temas)
temas<-data.frame(temas)
colnames(temas)<-c("Tema", "Frecuencia")

```


## Graficado

```
plotrix::pie3D(temas$Frecuencia,labels=paste(temas$Tema, temas$Frecuencia,
                                             collapse = NULL, sep= " "),
               explode=0.1, main="Cultura seg?n el Diario Sur")


```

# Extracción de los temas de Letras Libres

## Paquetes

```
library(tidytext)
library(tidyverse)
library(stopwords)
library(quanteda)
library(stm)
library(Rtsne)
library(rsvd)
library(geometry)
library(knitr)
library(plotrix)
library(igraph)

```


## Creación de inputs y filtrado de stopwords

```
# Creamos un df de stopwords para que sea el input de anti_join
stopwords<-data.frame(data_stopwords_stopwordsiso$es, 
                      rep("ISO", length(data_stopwords_stopwordsiso$es)))
colnames(stopwords)<-c("word", "lexicon")

# Creamos un df con articulos e id
articulos<-tibble(c(1:length(noticias.df$articulo)), 
                  as.character(noticias.df$articulo), 
                  as.character(noticias.df$medio),
                  as.character(noticias.df$autor),
                  as.character(noticias.df$fecha))
colnames(articulos)<-c("id", "articulo", "medio", "autor", "fecha")
LL<-articulos[which(articulos$medio=="Letras Libres"),]

# Ordenamos y filtramos stopwords
tidy_news <- LL %>%
  unnest_tokens(word, articulo) %>%
  anti_join(stopwords) %>%
  anti_join(stop_words)

# Creamos un dfm con los datos
news.dfm <- tidy_news %>%
  count(id, word, sort = TRUE) %>%
  tidytext::cast_dfm(id, word, n)

```


## Búsqueda de la cantidad de temas apropiada

```
# Extraemos los temas sin poner una cantidad
news.free.tm.swo <- stm(news.dfm, K = 0, verbose = FALSE, init.type = "Spectral")
labelTopics(news.free.tm.swo)
plot.STM(news.free.tm.swo ,type="summary", xlim=c(0, 0.1), n=7)

topicQuality(news.free.tm.swo, news.dfm)

# Buscamos una cantidad m?s precisa, pero antes preparamos los inputs
# y ampliamos la memoria
processed<-textProcessor(LL$articulo,customstopwords = stopwords$word)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta,
                     lower.thresh = 5,upper.thresh = 393)
palabras<-unique(tidy_news$word)
memory.limit(410241024*1024)

sk<-searchK(out$documents,palabras,K=c(10, 20, 30, 40, 50))
knitr::kable(sk$results)
plot(sk)

# En base a los resultados:
sk16_22<-searchK(out$documents, palabras, K=c(16,17,18,19,20,21,22))
knitr::kable(sk16_22$results)
plot(sk16_22)

```



## Extracción de los temas

```
# Parece que el n?mero apropiado de temas es 15

# Parece que el n?mero apropiado de temas es 18

news.18.tm <- stm(news.dfm, K = 18, verbose = FALSE, init.type = "Spectral")
labelTopics(news.18.tm, n=10)
plot.STM(news.18.tm,type="summary",xlim=c(0,0.2), n =7)
topicQuality(news.18.tm, news.dfm)


# Graficamos los temas

temas<-c("Pol?tica", "F?tbol", "Pol?tica", "Tecnolog?a", "Literatura", "Pol?tica",
         "Pol?tica", "Literatura", "Literatura", "Cine", "Cacer?as", "M?sica", 
         "Literatura", "Arte", "Cine", "Literatura", "Literatura", "Literatura")
temas<-table(temas)
temas<-data.frame(temas)
colnames(temas)<-c("Tema", "Frecuencia")

```


## Graficado

```
plotrix::pie3D(temas$Frecuencia,labels=paste(temas$Tema, temas$Frecuencia,
                                             collapse = NULL, sep= " "),
               explode=0.1, main="Cultura seg?n Letras Libres")

```
